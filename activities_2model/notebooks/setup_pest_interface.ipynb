{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup the PEST(++) interface around the enhanced Freyberg model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will construct a complex model independent (non-intrusive) interface around an existing `MODFLOW-NWT` model using the `python/flopy/pyemu` stack."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import flopy\n",
    "import pyemu\n",
    "import prep_deps\n",
    "import redis\n",
    "import matplotlib as mpl\n",
    "plt.rcParams['font.size']=12\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we define a base directory `b_d` from which we will read in a model already created `freyberg.nam`. This will form the basis of the remainder of the exercise (and those to follow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_d = os.path.join(\"..\",\"base_model_files\")\n",
    "nam_file = \"freyberg.nam\"\n",
    "b_d = os.path.join(\"temp_history\")\n",
    "nam_file = \"freyberg_hist.nam\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load the existing Freyberg model. This version should run but is not yet connected with `PEST++`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note that to load a model in a different folder, you supply the namefile without path and supply the path\n",
    "# to it in the model_ws variable\n",
    "m = flopy.modflow.Modflow.load(nam_file,model_ws=b_d,check=False,forgive=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### some visuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot some model attributes\n",
    "fig = plt.figure(figsize=(12,7))\n",
    "ax = plt.subplot(111,aspect=\"equal\")\n",
    "mm = flopy.plot.ModelMap(model=m)\n",
    "mm.plot_grid()\n",
    "mm.plot_ibound()\n",
    "mm.plot_bc('SFR')\n",
    "ax = mm.ax\n",
    "#m.wel.stress_period_data.plot(ax=ax,mflay=2)\n",
    "\n",
    "# plot obs locations\n",
    "obs = pd.read_csv(os.path.join(\"..\",\"base_model_files\",\"obs_loc.csv\"))\n",
    "                  \n",
    "obs_x = [m.sr.xcentergrid[r-1,c-1] for r,c in obs.loc[:,[\"row\",\"col\"]].values]\n",
    "obs_y = [m.sr.ycentergrid[r-1,c-1] for r,c in obs.loc[:,[\"row\",\"col\"]].values]\n",
    "ax.scatter(obs_x,obs_y,marker='.',label=\"water-level obs\",s=80)\n",
    "\n",
    "#plot names on the pumping well locations\n",
    "wel_data = m.wel.stress_period_data[0]\n",
    "wel_x = m.sr.xcentergrid[wel_data[\"i\"],wel_data[\"j\"]]\n",
    "wel_y = m.sr.ycentergrid[wel_data[\"i\"],wel_data[\"j\"]]\n",
    "for i,(x,y) in enumerate(zip(wel_x,wel_y)):\n",
    "    ax.scatter([x],[y],color=\"red\",marker=\"s\",s=50)\n",
    "    #ax.text(x,y,\"{0}\".format(i+1),ha=\"center\",va=\"center\")\n",
    "\n",
    "ax.set_ylabel(\"y(m)\")\n",
    "ax.set_xlabel(\"x(m)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### we can do a couple `flopy` things to move where the new model will be written"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign the executable name for the model\n",
    "m.exe_name = \"mfnwt\"\n",
    "\n",
    "# now let's run this in a new folder called temp so we don't overwrite the original data\n",
    "m.change_model_ws(\"temp\",reset_external=True)\n",
    "\n",
    "# this writes all the MODFLOW files in the new location \n",
    "m.write_input()\n",
    "\n",
    "# the following helps get the dependecies (both python and executables) in the right place\n",
    "prep_deps.prep_template(t_d=\"temp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### now we can run the model once using a `pyemu` helper\n",
    "This helper is particularly useful if you run on more than one platform (e.g. Mac and Windows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyemu.os_utils.run(\"{0} {1}\".format(m.exe_name,m.name+\".nam\"),cwd=m.model_ws)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### read in the heads and plot them up along with the budget components\n",
    "Note that there is a historic period and a scenario with future conditions that differ. \n",
    "\n",
    "_For the future scenario, a serious drought, recharge is lower and pumping/abstraction is increased to make up for the presumed deficite in water for agriculture._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "hds = flopy.utils.HeadFile(os.path.join(m.model_ws,m.name+\".hds\"),model=m)\n",
    "hds.plot(mflay=0)\n",
    "lst = flopy.utils.MfListBudget(os.path.join(m.model_ws,m.name+\".list\"))\n",
    "df = lst.get_dataframes(diff=True)[0]\n",
    "plt.figure()\n",
    "ax = df.plot(kind=\"bar\",figsize=(30,30), grid=True,subplots=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the effect of the \"scenario\" in the second stress period with less recharge and more abstraction. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot depth to water"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtw = m.dis.top.array - hds.get_data()[0,:,:]\n",
    "dtw = np.ma.masked_where(m.bas6.ibound[0].array==0,dtw)\n",
    "c = plt.imshow(dtw)\n",
    "plt.title('Depth to Water')\n",
    "plt.colorbar(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can see the river and well locations expressed in the depth to water pattern."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup data structures related to what we want to parameterize and what we want to observe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### first the parameterization of model inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "props = []\n",
    "# here we specify which packages we wish to parameterize, \n",
    "# starting with those that do not change over time\n",
    "paks = [\"upw.hk\",\"upw.vka\",\"upw.ss\",\"upw.sy\",\"bas6.strt\",\"extra.prsity\"]  #\"extra\" because not a modflow parameter\n",
    "for k in range(m.nlay):\n",
    "    props.extend([[p,k] for p in paks])\n",
    "# next we specify that we want to make parameters for recharge\n",
    "# for both stress periods (zero-based! Python style)\n",
    "for kper in range(m.nper):\n",
    "    props.append([\"rch.rech\",kper])\n",
    "props"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### we want to handle list-type parameters in two ways\n",
    "for `spatial_list_props` this will apply a multiplier distributed spatially that applied in all stress periods throughout the model\n",
    "\n",
    "for `temporal_list_props` this will apply a multiplier for each stress period applied to all the spatial locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spatial_list_props = [[\"wel.flux\",2],[\"drn.cond\",0]]  # spatially by each list entry, across all stress periods\n",
    "temporal_list_props = [[\"wel.flux\",kper] for kper in range(m.nper)]  # spatially uniform for each stress period\n",
    "\n",
    "spatial_list_props, temporal_list_props"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### next we want to set up the extraction of model outputs for which we have observations. First, we will setup a post-processor that will read the heads for all active cells in both stress periods - why not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "hds_kperk = [[kper,k] for k in range(m.nlay) for kper in range(m.nper)]\n",
    "#hds_kperk.extend([[1,k] for k in range(m.nlay)])\n",
    "\n",
    "hds_kperk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### then we setup monitoring of the SFR ASCII outputs.  \n",
    "we will accumulate the first 20 reaches and last 20 reaches (corresponding to the top and bottom half of the model, respectively) together to form forecasts of sw-gw exchange in the headwaters (`hw`) and tailwaters (`tw`).  Then we will also add each reach individually for monitoring as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sfr_obs_dict = {}\n",
    "sfr_obs_dict[\"hw\"] = np.arange(1,int(m.nrow/2))\n",
    "sfr_obs_dict[\"tw\"] = np.arange(int(m.nrow/2),m.nrow)\n",
    "for i in range(m.nrow):\n",
    "    sfr_obs_dict[i] = i+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### here we go...\n",
    "\n",
    "This `pyemu` class has grown into a monster...it does (among other things):\n",
    "- sets up combinations of multiplier parameters for array inputs, including uniform, zones, pilot points, grids, and KL expansion types\n",
    "- sets up combinations of multiplier parameters for list inputs\n",
    "- handles several of the shitty modflow exceptions to the array and list style inputs\n",
    "- sets up large numbers of observations based on arrays or time series\n",
    "- writes .tpl, .ins, .pst, etc\n",
    "- writes a python forward run script\n",
    "- writes a prior parameter covaraince matrix using geostatistical correlations\n",
    "- draws from the prior parameter covariance matrix to generate a prior parameter ensemble\n",
    "\n",
    "WAT?!\n",
    "\n",
    "This will be slow because the pure python kriging...but, hey, its free!\n",
    "\n",
    "For our purposes, we will setup combinations of constant (by layer), pilot points and grid-scale parameters for each of the array-based properties we defined earlier.  This lets us explore options for parameterization and also start to understand how information flows in the history matching problem\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pst_helper = pyemu.helpers.PstFromFlopyModel(nam_file,new_model_ws=\"template\",org_model_ws=\"temp\",\n",
    "                                             const_props=props,spatial_list_props=spatial_list_props,\n",
    "                                             temporal_list_props=temporal_list_props,remove_existing=True,\n",
    "                                             grid_props=props,pp_props=props,sfr_pars=True,hds_kperk=hds_kperk,\n",
    "                                             sfr_obs=sfr_obs_dict,build_prior=False,model_exe_name=\"mfnwt\",\n",
    "                                             pp_space=4)\n",
    "prep_deps.prep_template(t_d=pst_helper.new_model_ws)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `pst_helper` instance contains the `pyemu.Pst` instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# so, pull out the `pyemu.Pst` instance which \n",
    "#contains all the input that ultimately goes in the PEST control %%file\n",
    "pst = pst_helper.pst\n",
    "pst.npar,pst.nobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oh snap!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pyemu` uses `pandas` data frame format for the parameter and observation data sections. This offers plenty of querying and bulk editing options.\n",
    "\n",
    "Let's stop for a moment to get a better feel for what just happened! Let's dig in.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# check out hydraulic conductivity parameters\n",
    "pst.parameter_data.loc[pst.parameter_data.parnme.apply(lambda x: \"hk\" in x),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what about observations? in particular, the sfr flow-out observations?\n",
    "pst.observation_data.loc[pst.observation_data.obgnme.apply(lambda x: \"flout\" in x),:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add modpath input files, instruction files and calls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First copy over all the MODPATH-related files from the base directory identified in the `b_d` variable.   We will track a single particle for forecast purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_files = [f for f in os.listdir(b_d) if \"mp\" in f or \"location\" in f]\n",
    "[shutil.copy2(os.path.join(b_d,f),os.path.join(pst_helper.new_model_ws,f)) for f in mp_files]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following `frun_post_lines` property adds statements at the end of the `forward_run.py` script. In this case, it runs MODPATH using `mp6`.  We will also identify any additional temporary files that the forward run script will attempt to remove at the start of a run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pst_helper.frun_post_lines.append(\"os.system('mp6 freyberg.mpsim >mp6.stdout')\")\n",
    "pst_helper.frun_post_lines.append(\"pyemu.os_utils.run('mp6 freyberg.mpsim >mp6.stdout')\")\n",
    "pst_helper.tmp_files.append(\"freyberg.mpenpt\")  # placed at top of `forward_run.py`\n",
    "pst_helper.write_forward_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create and add instruction files and related observations for MODPATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_file = \"freyberg.mpenpt\"\n",
    "ins_file = out_file + \".ins\"\n",
    "with open(os.path.join(pst_helper.new_model_ws,ins_file),'w') as f:\n",
    "    f.write(\"pif ~\\n\")\n",
    "    f.write(\"l7 w w w !part_status! w w !part_time!\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pst_helper.pst.add_observations(os.path.join(pst_helper.new_model_ws,ins_file),\n",
    "                                     os.path.join(pst_helper.new_model_ws,out_file),\n",
    "                                     pst_path=\".\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need to copy the original prsity arrays to the `arr_org` dir for use in the multiplier parameterization scheme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(m.nlay):\n",
    "    np.savetxt(os.path.join(pst_helper.new_model_ws,\"arr_org\",\"prsity_layer_{0}.ref\".format(k+1)),\n",
    "               np.zeros((m.nrow,m.ncol))+0.001,fmt=\"%15.6E\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final bits and bobs\n",
    "We need to set some realistic parameter bounds and account for expected (but stochastic) scenario conditions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "par = pst.parameter_data  # we inspected this guy earlier\n",
    "# properties\n",
    "tag_dict = {\"hk\":[0.1,10.0],\"vka\":[0.1,10],\"strt\":[0.95,1.05],\"pr\":[0.8,1.2]}\n",
    "for t,[l,u] in tag_dict.items():\n",
    "    t_pars = par.loc[par.parnme.apply(lambda x: t in x ),\"parnme\"]\n",
    "    par.loc[t_pars,\"parubnd\"] = u\n",
    "    par.loc[t_pars,\"parlbnd\"] = l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "given the combinations of multipliers, we need to set a hard upper bound on sy since it has a physical upper limit (note: seperate to bounds handled explicitly by pest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_csv = os.path.join(pst_helper.new_model_ws,\"arr_pars.csv\")\n",
    "df = pd.read_csv(arr_csv,index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sy_pr = df.model_file.apply(lambda x: \"sy\" in x or \"pr\" in x)\n",
    "df.loc[:,\"upper_bound\"] = np.NaN\n",
    "df.loc[sy_pr,\"upper_bound\"] = 0.4\n",
    "df.to_csv(arr_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# table can also be written to a .tex file (report-ready!)\n",
    "pst.write_par_summary_table(filename=\"none\").sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pst.write_obs_summary_table(filename=\"none\").head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's run the process once (`noptmax=0`) to make sure its all plumbed up.  Pro-tip: you can use any of the `pestpp-###` binaries/executables to run `noptmax=0`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pst.control_data.noptmax = 0\n",
    "pst.write(os.path.join(pst_helper.new_model_ws,\"freyberg.pst\"))\n",
    "pyemu.os_utils.run(\"pestpp-ies freyberg.pst\",cwd=pst_helper.new_model_ws)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's take it up a notch. We need to generate the prior parameter covariance matrix and stochastic realizations.  We will use the geostatistical covariance information in the `pst_helper` instance for this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if pst_helper.pst.npar < 15000:\n",
    "    cov = pst_helper.build_prior(fmt=\"coo\",filename=os.path.join(pst_helper.new_model_ws,\"prior_cov.jcb\"))\n",
    "    cov = np.ma.masked_where(cov.x==0,cov.x)\n",
    "    try:\n",
    "        fig = plt.figure(figsize=(10,10))\n",
    "        ax = plt.subplot(111)\n",
    "        ax.imshow(cov)\n",
    "        plt.show()\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### now we can make a draw from the prior parameter covariance matrix to form a prior parameter ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pe = pst_helper.draw(500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that parameters are treated in parameter group (`pargp`) blocks for this ensemble generation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Always a good idea to inspect the parameter ensemble for reasonableness! Can do via slicing and dicing..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pe.iloc[-10:-5,:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot one parameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "par = pst_helper.pst.parameter_data\n",
    "pyemu.plot_utils.ensemble_helper(pe,plot_cols=par.groupby(\"pargp\").groups,bins=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thoughts? Do these look reasonable? We see log-normal distributions for log-transformed parameters, e.g., hk... looking good!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to enforce parameter bounds and save this ensemble for later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pe.enforce()  # always a good idea!\n",
    "pe.to_binary(os.path.join(pst_helper.new_model_ws,\"prior.jcb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### set weights for \"observations\" and identify forecasts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next major task is to set the weights on the observations.  So far, in the `pst_helper` process, we simply identified what outputs from the model we want to \"observe\".  We now use a pre-cooked csv file to set nonzero weights only for GW level observation locations used in the original Freyberg model.  We will also use the SFR flow out of the last reach (`fo` in the last row in `19791230`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_locs = pd.read_csv(os.path.join(\"..\",\"base_model_files\",\"obs_loc.csv\"))\n",
    "#build obs names that correspond to the obsnme values in the control file\n",
    "obs_locs.loc[:,\"obsnme\"] = obs_locs.apply(lambda x: \"hds_00_{0:03d}_{1:03d}_000\".format(x.row-1,x.col-1),axis=1)\n",
    "obs_locs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set all weights to zero first, then turn on the weights at only a few locations.  These nonzero obs will be given meaningful weights in the prior monte carlo excercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = pst.observation_data\n",
    "obs.loc[:,\"weight\"] = 0.0\n",
    "obs.loc[obs_locs.obsnme,\"weight\"] = 1.0\n",
    "obs.loc[obs_locs.obsnme,\"obgnme\"] = \"calhead\"\n",
    "fo_obs = \"fo_{0}_19791230\".format(pst_helper.m.nrow-1)\n",
    "obs.loc[fo_obs,\"weight\"] = 1.0\n",
    "obs.loc[fo_obs,\"obgnme\"] = \"calflux\"\n",
    "pst.nnz_obs_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will define which model outputs are going to be treated as \"forecasts\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "swgw_forecasts = obs.loc[obs.obsnme.apply(lambda x: \"fa\" in x and (\"hw\" in x or \"tw\" in x)),\"obsnme\"].tolist()\n",
    "\n",
    "hds_fore_name = \"hds_00_{0:03d}_{1:03d}\".format(int(pst_helper.m.nrow/3),int(pst_helper.m.ncol/10))\n",
    "hds_forecasts = obs.loc[obs.obsnme.apply(lambda x: hds_fore_name in x),\"obsnme\"].tolist()\n",
    "forecasts = swgw_forecasts\n",
    "forecasts.extend(hds_forecasts)\n",
    "forecasts.append(\"part_time\")\n",
    "forecasts.append(\"part_status\")\n",
    "pst_helper.pst.pestpp_options[\"forecasts\"] = forecasts\n",
    "forecasts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After all these changes to the pst object, we need to re-write the pcf!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pst.write(os.path.join(pst_helper.new_model_ws,\"freyberg.pst\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run one last time.  `phi` should be near zero since we haven't change the `parval1` values for historic stress period and only the 13 gw level obs have nonzero weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyemu.os_utils.run(\"pestpp-ies.exe freyberg.pst\",cwd=pst_helper.new_model_ws)\n",
    "pst = pyemu.Pst(os.path.join(pst_helper.new_model_ws,\"freyberg.pst\"))\n",
    "pst.phi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = flopy.utils.MfListBudget(os.path.join(\"template\",\"freyberg.list\"))\n",
    "df = lst.get_dataframes(diff=True)[0]\n",
    "df.plot(kind=\"bar\",figsize=(10,10), grid=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
